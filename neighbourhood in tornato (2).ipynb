{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Battle of Neighborhoods\n",
    "   \n",
    "   ###  Course: Applied Data Science Capstone\n",
    "   \n",
    "This notebook would contain Explaination and code for the coursera Capstone Project. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Adding Required Libraries to create required Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # library to handle data in a vectorized manner\n",
    "\n",
    "import pandas as pd # library for data analsysis\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Print Statement !! :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello Capstone Project Course!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmenting and Clustering Neighborhoods in Toronto\n",
    "\n",
    "## 1. Data scraping\n",
    "\n",
    "#### Description: \n",
    "Code to scrape the following Wikipedia page, https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M, in order to obtain the data that is in the table of postal codes and to transform the data into a pandas dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataframe columns\n",
    "column_names = ['Postal_Code','Borough', 'Neighborhood'] \n",
    "\n",
    "# instantiate the dataframe\n",
    "nbr = pd.DataFrame(columns=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the empty dataframe to confirm that the columns are as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web scraping\n",
    "##### Importing Data From provided URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the library used to query a website\n",
    "from urllib.request import urlopen\n",
    "\n",
    "#specify the url\n",
    "wiki = \"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\"\n",
    "\n",
    "#Query the website and return the wiki to the variable 'page'\n",
    "page = urlopen(wiki)\n",
    "\n",
    "#import the Beautiful soup functions to parse the data returned from the website\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Parse the html in the 'page' variable, and store it in Beautiful Soup format\n",
    "soup = BeautifulSoup(page, \"lxml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below to Print HTML of the Page\n",
    "#print(soup.prettify()) \n",
    "\n",
    "#Get table \n",
    "right_table=soup.find('table', class_='wikitable sortable')\n",
    "# uncomment below to print table\n",
    "#right_table  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract the information to DataFrame: \n",
    "we iterate through each row (tr) and then assign each element of tr (td) to a variable and append it to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate lists\n",
    "A=[]\n",
    "B=[]\n",
    "C=[]\n",
    "\n",
    "for row in right_table.findAll(\"tr\"):\n",
    "    cells = row.findAll('td')\n",
    "    if len(cells)==3: #Only extract table body not heading\n",
    "        A.append(cells[0].find(text=True))\n",
    "        B.append(cells[1].find(text=True))\n",
    "        C.append(cells[2].find(text=True))\n",
    "\n",
    "        \n",
    "#Adding Data to our DataFrame\n",
    "nbr['Postal_Code']=A\n",
    "nbr['Borough']=B\n",
    "nbr['Neighborhood']=C\n",
    "\n",
    "#uncomment below to view dataframe nbr which contains data as retreived from the webpage in wiki\n",
    "#nbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Ignore cells with a borough that is Not assigned.\n",
    "1. Compare with Each row if Borough is Not Assigned drop row.\n",
    "2. Reset Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr = nbr.drop(nbr[nbr['Borough'].str.contains(\"Not assigned\")==True].index, axis=0, inplace=False)\n",
    "\n",
    "#Reset Index\n",
    "nbr.index = pd.RangeIndex(len(nbr.index))\n",
    "\n",
    "#Uncomment below to view Dataframe where not Assigned Boroughs have been dropped out.\n",
    "#nbr               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If a cell has a borough but a Not assigned neighborhood, then the neighborhood will be the same as the borough.\n",
    "1. instantiate additional dataframe nbrNA\n",
    "2. Compare with Each row if Neighborhood is Not Assigned add value from Borough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate additional dataframe nbrNA\n",
    "column_n = ['NBRVAL'] \n",
    "nbrNA = pd.DataFrame(columns=column_n)\n",
    "D=['Not assigned'] \n",
    "nbrNA['NBRVAL'] = D\n",
    "\n",
    "#Dataframe contains 'Not assigned' value used for Comparison.\n",
    "#print(nbrNA)\n",
    "\n",
    "nbr1=nbr\n",
    "#nbr1\n",
    "\n",
    "\n",
    "#Compare with Each row if Neighborhood is Not Assigned add value from Borough.\n",
    "for row_index,row in nbr.iterrows():\n",
    "    if((nbr.loc[row_index,['Neighborhood']].values.astype('str') == 'Not assigned') or (nbr.loc[row_index,['Neighborhood']].values.astype('str') == 'Not assigned\\n')):\n",
    "        #print('inside if')\n",
    "        nbr1.loc[row_index,['Neighborhood']] = nbr1.loc[row_index,['Borough']].values.astype('str') \n",
    "        \n",
    "#Reset Index\n",
    "#nbr.index = pd.RangeIndex(len(nbr.index))\n",
    "\n",
    "#Uncomment below to view Dataframe nbr1 which contains Neighborhoods which were initially 'Not Assigned' now containing Borough values\n",
    "print('nbr1')\n",
    "nbr1               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More than one neighborhood can exist in one postal code area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr2=nbr1.groupby('Postal_Code').agg({'Borough':'first',\n",
    "                               'Neighborhood': ', '.join}).reset_index()\n",
    "#Uncomment Below to view nbr2 which contains grouped Boroughs\n",
    "nbr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing the number of rows of neighborhoods dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nbr2.shape)\n",
    "print('nbr2')\n",
    "nbr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Neighborhood\n",
    "Creating a copy of Dataframe.\n",
    "Dropping neighborhoods which do not Belong to Toronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataframe columns\n",
    "column_names = ['Postal_Code','Borough', 'Neighborhood'] \n",
    "# instantiate the dataframe\n",
    "neighbor = pd.DataFrame(columns=column_names)\n",
    "\n",
    "neighbor = nbr2.drop(nbr2[nbr2['Borough'].str.contains(\"Toronto\")==False].index, axis=0, inplace=False)\n",
    "\n",
    "#Reset Index\n",
    "neighbor.index = pd.RangeIndex(len(neighbor.index))\n",
    "print('neighbor')\n",
    "print(neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping nbr_ungrp for ease of location calculations, using nbr1 by dropping Non Toronto Boroughs.\n",
    "# define the dataframe columns\n",
    "column_names = ['Postal_Code','Borough', 'Neighborhood'] \n",
    "# instantiate the dataframe\n",
    "nbr_ungrp = pd.DataFrame(columns=column_names)\n",
    "\n",
    "nbr_ungrp = nbr1.drop(nbr1[nbr1['Borough'].str.contains(\"Toronto\")==False].index, axis=0, inplace=False)\n",
    "\n",
    "#Reset Index\n",
    "nbr_ungrp.index = pd.RangeIndex(len(nbr_ungrp.index))\n",
    "\n",
    "#Uncomment below to view Dataframe\n",
    "print(nbr_ungrp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing Longitude And Latitude info of Locations\n",
    "using the Geocoder Python package instead: https://geocoder.readthedocs.io/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this line if you haven't completed the Foursquare API lab\n",
    "!conda install -c conda-forge geopy --yes \n",
    "# convert an address into latitude and longitude values\n",
    "import time\n",
    "from geopy.geocoders import Nominatim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looping through locations to fetch Latitude and Longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"my_app app123\")\n",
    "#print('here')\n",
    "\n",
    "for row_index, item in nbr_ungrp.iterrows():\n",
    "    \n",
    "    list1 = nbr_ungrp.loc[[row_index],['Neighborhood']].values.astype('str')\n",
    "    loc = ' , Toronto, Ontario, Canada'\n",
    "    list1.astype('str')\n",
    "    list1 = np.append(list1, loc)\n",
    "    latitude = None\n",
    "    longitude = None\n",
    "    location = None\n",
    "    \n",
    "    location = geolocator.geocode(list1 , limit = 15)\n",
    "    #print(loc)\n",
    "    #print(row_index)\n",
    "    time.sleep(5)\n",
    "    if(location is not None):\n",
    "        #print(location)\n",
    "        #print(\"location Address : \")\n",
    "        #print(location.address)\n",
    "        #print('latitude, longitude : ')\n",
    "        #print((location.latitude, location.longitude))\n",
    "        nbr_ungrp.loc[nbr_ungrp.index[row_index], 'Latitude'] = location.latitude\n",
    "        nbr_ungrp.loc[nbr_ungrp.index[row_index], 'Longitude'] = location.longitude\n",
    "        #print(nbr_ungrp[row_index])    \n",
    "\n",
    "print(nbr_ungrp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood analysis#\n",
    "# Importing Libraries for Foursqaue to analyse Neighborhood.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # library to handle JSON files\n",
    "\n",
    "import requests # library to handle requests\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n",
    "\n",
    "# Matplotlib and associated plotting modules\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Importing to use the Foursquare API lab\n",
    "!conda install -c conda-forge folium=0.5.0 --yes \n",
    "import folium # map rendering library\n",
    "\n",
    "print('Foursquare and map plotting Libraries imported.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Boroughs and Neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The dataframe has {} boroughs and {} neighborhoods.'.format(\n",
    "        len(nbr_ungrp['Borough'].unique()),\n",
    "        nbr_ungrp.shape[0]\n",
    "    )\n",
    ")\n",
    "\n",
    "#Dropping NANs\n",
    "nbr_ungrp.dropna(inplace =True)\n",
    "#Reset Index\n",
    "nbr_ungrp.index = pd.RangeIndex(len(nbr_ungrp.index))\n",
    "nbr_ungrp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using geopy library to get the latitude and longitude values of Toronto City."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'Toronto, Ontario, Canada'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"my-app123\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Toronto are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a map of Toronto with neighborhoods superimposed on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map of Toronto using latitude and longitude values\n",
    "map_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n",
    "\n",
    "# add markers to map\n",
    "for lat, lng, borough, neighborhood in zip(nbr_ungrp['Latitude'], nbr_ungrp['Longitude'], nbr_ungrp['Borough'], nbr_ungrp['Neighborhood']):\n",
    "    label = '{}, {}'.format(neighborhood, borough)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_toronto)  \n",
    "    \n",
    "map_toronto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we are going to start utilizing the Foursquare API to explore the neighborhoods and segment them.\n",
    "#### Define Foursquare Credentials and Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore the first neighborhood in our dataframe.\n",
    "Get the neighborhood's details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_ungrp.loc[0]\n",
    "neighborhood_latitude = np.float(nbr_ungrp.loc[0,['Latitude']].values)\n",
    "neighborhood_longitude =  np.float(nbr_ungrp.loc[0,['Longitude']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's get the top 25 venues that are in Harbourfront within a radius of 500 meters.\n",
    "First, let's create the GET request URL. Naming the URL url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code was removed by Watson Studio for sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  get_category_type function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that extracts the category of the venue\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning the json and structuring it into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues = results['response']['groups'][0]['items']\n",
    "    \n",
    "nearby_venues = json_normalize(venues) # flatten JSON\n",
    "\n",
    "# filter columns\n",
    "filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "nearby_venues =nearby_venues.loc[:, filtered_columns]\n",
    "\n",
    "# filter the category for each row\n",
    "nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
    "\n",
    "# clean columns\n",
    "nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n",
    "\n",
    "nearby_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " how many venues were returned by Foursquare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring all Neighborhoods-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting Toronto Venues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_venues = getNearbyVenues(names=nbr_ungrp['Neighborhood'],\n",
    "                                   latitudes=nbr_ungrp['Latitude'],\n",
    "                                   longitudes=nbr_ungrp['Longitude']\n",
    "                                  )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(toronto_venues.shape)\n",
    "toronto_venues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many venues were returned for each neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_venues.groupby('Neighborhood').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's find out how many unique categories can be curated from all the returned venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} uniques categories.'.format(len(toronto_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Each Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "toronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "toronto_onehot['Neighborhood'] = toronto_venues['Neighborhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\n",
    "toronto_onehot = toronto_onehot[fixed_columns]\n",
    "\n",
    "toronto_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's group rows by neighborhood and by taking the mean of the frequency of occurrence of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "toronto_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_grouped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print each neighborhood along with the top 5 most common venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "\n",
    "for hood in toronto_grouped['Neighborhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = toronto_grouped[toronto_grouped['Neighborhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's put that into a *pandas* dataframe\n",
    "First, let's write a function to sort the venues in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the new dataframe and display the top 7 venues for each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 7\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighborhoods_venues_sorted['Neighborhood'] = toronto_grouped['Neighborhood']\n",
    "\n",
    "for ind in np.arange(toronto_grouped.shape[0]):\n",
    "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cluster Neighborhoods\n",
    "Run *k*-means to cluster the neighborhood into 4 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters\n",
    "kclusters = 4\n",
    "\n",
    "toronto_grouped_clustering = toronto_grouped.drop('Neighborhood',1)\n",
    "#print(toronto_grouped_clustering)\n",
    "#print(toronto_grouped)\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(init = \"k-means++\", n_clusters=kclusters, random_state=0).fit(toronto_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "labels = kmeans.labels_[0:63] \n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new dataframe that includes the cluster as well as the top 10 venues for each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_merged = nbr_ungrp\n",
    "print(toronto_merged.shape)\n",
    "labels = np.append(labels,labels[0])\n",
    "print(labels.shape)\n",
    "# add clustering labels\n",
    "toronto_merged['Cluster Labels'] = labels.tolist()\n",
    "\n",
    "# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\n",
    "toronto_merged = toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n",
    "\n",
    "toronto_merged.head() # check the last columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's visualize the resulting clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map\n",
    "map_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i+x+(i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'], toronto_merged['Neighborhood'], toronto_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Examine Clusters\n",
    "#### Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == 0, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == 1, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == 2, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toronto_merged.loc[toronto_merged['Cluster Labels'] == 3, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
